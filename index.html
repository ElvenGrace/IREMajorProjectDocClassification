<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Wikipedia Document Classification</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/blog-post.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

   

    <!-- Page Content -->
    <div class="container">

        <div class="row">

            <!-- Blog Post Content Column -->
            <div class="col-lg-8">

                <!-- Blog Post -->

                <!-- Title -->
                <h1>Wikipedia Document Classification</h1>

                <!-- Author -->
                <p class="lead">
                    by <a href="#">Mohit Sharma, Vijjini Anvesh Rao, T.V.Ravi Teja</a>
                </p>

                <hr>

                <hr>


                <hr>

                <!-- Post Content -->
                <p class="lead"> Aim </p>
                <p>Given a Wikipedia Document our aim is to say the Categories it may belong to, based on a Training data in which each Document is tagged to multiple Categories,  The Categories we considered are the following: </p>
                    <b>Wiki</b><br/>
                   <b> Art</b><br/>
                    <b>Reference</b><br/>
                   <b> People</b><br/>
                   <b> Culture</b><br/>
                   <b> Books</b><br/>
                   <b> Design</b><br/>
                   <b> Politics</b><br/>
                   <b> Technology</b><br/>
                    <b>Psychology</b><br/>
                    <b>Interesting</b><br/>
                    <b>Wikipedia</b><br/>
                    <b>Research</b><br/>
                    <b>Religion</b><br/>
                    <b>Music</b><br/>
                    <b>Math</b><br/>
                    <b>Development</b><br/>
                    <b>Theory</b><br/>
                    <b>Philosophy</b><br/>
                   <b> Article</b><br/>
                    <b>Language</b><br/>
                    <b>Science</b><br/>
                    <b>Programming</b><br/>
                    <b>History</b><br/>
                    <b>Software</b><br/></br>
                <p class="lead"> Dataset </p>
                <p>We used Wiki10+ data set from following link:</br>
                    <a href="http://nlp.uned.es/social-tagging/wiki10+/">http://nlp.uned.es/social-tagging/wiki10+/</a></br></br>
                The data set contains following two files:</br>
                1) wiki10+_tag-data.tar.gz  (3,6 MB): Contains all the tag data for the Wikipedia articles.</br>
                2) wiki10+_documents.tar.bz2  (271 MB): Content for all the Wikipedia articles on the dataset in HTML format. We extracted the text from HTML to run different experiments.</br></br>
                As we only consider top 25 documents, we removed those documents who don't have even one of these top 25 categories</br>
                This dataset is made up by 20,764 unique URLs, all of them with their corresponding social tags. All of them are English Wikipedia articles with at least 10 annotations on Delicious. Therefore, the tag information for each of these Wikipedia articles as well as the text content can be found in this dataset.</br></br></p>
                <p class="lead"> Approach 1:  LDA or Latent Dirichlet Allocation </p>
                <p>We can use LDA to classify documents in different tags. We know that LDA divides the given corpus in fixed no. of topics and can also provide which topics are contained in a document and with what probability. For the experiments performed  using LDA, we don’t need to worry about internal implementation of LDA. We used gensim’s implementation of LDA. To use the library, we just need to know few points about input and output format.</p>
                </br>
                <b> During Learning phase</b></br></br>
                <b>INPUT:</b>
                </br><p>We provide all the wiki documents in single XML file zipped in bz2 format.</p>
                 <b>LEARNT MODEL:</b>
                </br><p>Word distribution for each topic eg: “topic #0: 0.009*river + 0.008*lake + 0.006*island + 0.005*mountain + 
                0.004*area + 0.004*park + 0.004*antarctic + 0.004*south + 0.004*mountains + 0.004*dam”</p>
                 <b> During Testing phase</b></br></br>
                  <b>INPUT:</b>
                </br><p>We provide the document to be classified in bag of words form to the learnt model</p>
                <b>OUTPUT:</b>
                </br><p>Topic distribution for a the text eg: “[(34, 0.023705742561150572), (60, 0.017830310671555303), (62, 0.023999239610385081), (83,0.029439444128473557), (87, 0.028172479800878891), (90, 0.1207424163376625), (116,0.022904510579689157)]”  represents the probabilities of the doc to fall under topics like 34,60,62….</p></br>
           


                <p class="lead"> Major challenge in classification:  </p>
                <p>It seems to be fairly simple to classify a document in different topics as we can see in output of testing phase. But  our aim is to classify the document under different tags like “politics, science” etc. and not under topic numbers. </p>
                 <p class="lead"> Possible Solutions: </p>
                <p>Clearly we need some way to map all the topics learnt by LDA to the most suitable tags. If we are able to do this then we simply test the unknown text against the model learnt by LDA and then report the tag corresponding to the topic given by LDA in output. We tried two different solutions to map topics to the tags: </p>
                <p>1). As each topic of LDA is represented by distribution of words. We can create a query by combining those words and find best matched document on tf-idf basis for that query. That particular document must be the best match for that topic. So we can map the topic to tag of best matched document.</p>
                <p>2) We can find probability distribution of topics for all the documents. Represent each document as a topic vector. Now find the closest document or the most similar document for each topic. Map the topic to the tag of that particular document.</p>

                <b>Approach 1: </b><br>
                <p>We can specify the major steps of to implement this approach as follows:</p>
                <p>1) Divide the documents in training and test data with 4000 docs in test data.</p>
                <p>2) On training data run gensim's LDA and save the learnt model. Set the number of topics as 300.</p>
                <p>3) Save all the topics in a file and convert them to queries.</p>
                <b>  Example topic:</b><br>
                <p>2016-04-06 00:05:52,466 : INFO : topic #299 (0.003): 0.014*insurance + 0.009*scott + 0.007*samurai + 0.007*hipster + 0.006*forecasting + 0.006*fbi + 0.006*imf +     0.005*skeptical + 0.005*bass + 0.005*hidden</p>
                <b>Query corresponding to above topic  #299:</b><br>
                <p> 299:insurance scott samurai hipster forecasting fbi imf skeptical bass hidden</p>
                <p>4) For each query, retrieve the most relevant document in training set on tf-idf basis and create topic to doc Id mapping.</p>
                 <b>         Example:</b><br>
                <p>   299 : cae3757420fbc4008bbfe492ab0d4cb5</p>

                <hr>

                <!-- Blog Comments -->

                <!-- Comments Form -->
                <hr>

                <!-- Posted Comments -->

               
                

            <!-- Blog Sidebar Widgets Column -->
            
        </div>
        <!-- /.row -->

        <hr>

        <!-- Footer -->
        <footer>
            <div class="row">
                <div class="col-lg-12">
                    <p>Copyright &copy; Your Website 2016</p>
                </div>
            </div>
            <!-- /.row -->
        </footer>

    </div>
    <!-- /.container -->

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>
